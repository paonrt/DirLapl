% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slm_DirLapl_mcmc.R
\name{slm_DirLapl_mcmc}
\alias{slm_DirLapl_mcmc}
\title{Simplified Linear Model with Dirichlet-Laplace Prior: Markov Chain
Monte Carlo Algorithm}
\usage{
slm_DirLapl_mcmc = function(nsim, X, sigmaSq, y, alpha, start = NULL,
                                   burn = 0, thin = 1, verbose = +Inf)
}
\arguments{
\item{nsim}{The number of simulations.}

\item{X}{The design matrix.}

\item{sigmaSq}{The known value of the variance.}

\item{y}{The response vector.}

\item{alpha}{The hyper-parameter controlling the amount of shrinkage.}

\item{start}{The starting point.}

\item{burn}{The number of draws to be discarded as burn-in.}

\item{thin}{The thinning parameter.}

\item{verbose}{The period for printing status of the chain.}
}
\value{
Posterior sample of the parameters.
}
\description{
Gibbs sampler algorithm for the linear model with no intercept
and known variance. A Dirichlet-Laplace prior is used for the vector of the
coefficients.
}
\details{
Linear regression model with no intercept and known variance, say
\deqn{
 y \sim N_n (X \beta, \sigma^2 I_n)
}
where \eqn{I_n} is the \eqn{n}-dimensional identity matrix. The prior on the
coefficient vector \eqn{\beta} is the Dirichlet-Laplace prior:
\deqn{
 \beta_i \overset{ind}{\sim} N(0, \sigma^2 \delta^2_i \psi_i) \, , \,
  \delta_i \overset{i.i.d.}{\sim} \mathrm{gamma}(\alpha, 1 / 2)
  \perp\!\!\!\perp \psi_i \overset{i.i.d.}{\sim} \exp(1 / 2)
 }
or, equivalently
\deqn{
  \beta_i \overset{ind}{\sim} N(0, \sigma^2 \tau^2 \phi^2_i \psi_i) \\
  \tau \sim \mathrm{gamma}(n \alpha, 1 / 2) \\
  \phi \sim \mathrm{Dirichlet}_n(\alpha, \alpha, \dots, \alpha) \\
  \psi_i \overset{i.i.d.}{\sim} \exp(1 / 2)
 }
For the Gibbs sampler, it is used the first representation.

\code{start}: the starting point is generated in the following way:
\itemize{
\item if \code{start == NULL} then set the starting point of \code{beta}
from elastic net.
\item \code{else} set the starting point for \code{beta} equal to
\code{start}.
}

Only one value every \code{thin} values is kept in the chain, so the true
number of complete scans will be \code{nsim * thin + burn}. By default
\code{thin = 1}, that is no thinning.

The current time and the current number of iteration are printed one every
\code{verbose} iterations. Furthermore:
\itemize{
\item if \code{verbose == +-Inf} then there is no printing,
\item if \code{verbose != +-Inf} then at least start and end of simulation
are reported.
}
}
